import streamlit as st
import google.generativeai as genai
import numpy as np
import soundfile as sf
import json
import re
import matplotlib.pyplot as plt
import matplotlib

# --- [‡∏™‡πà‡∏ß‡∏ô‡∏ó‡∏µ‡πà 1: ‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏°‡∏£‡∏∞‡∏ö‡∏ö (Setup)] ---
matplotlib.use('Agg') # ‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤‡∏Å‡∏£‡∏≤‡∏ü‡πÑ‡∏°‡πà‡πÉ‡∏´‡πâ‡∏ï‡∏µ‡∏Å‡∏±‡∏ö Server
st.set_page_config(page_title="SYNAPSE: FINAL REAL", page_icon="üß¨")

# ‡πÄ‡∏ä‡πá‡∏Ñ‡∏Å‡∏∏‡∏ç‡πÅ‡∏à (‡∏ñ‡πâ‡∏≤‡πÑ‡∏°‡πà‡∏°‡∏µ Key ‡πÇ‡∏Ñ‡πâ‡∏î‡∏ô‡∏µ‡πâ‡πÄ‡∏õ‡πá‡∏ô‡πÅ‡∏Ñ‡πà‡πÄ‡∏®‡∏©‡∏Å‡∏£‡∏∞‡∏î‡∏≤‡∏©)
if "GEMINI_API_KEY" not in st.secrets:
    st.error("‚õî CRITICAL: ‡πÑ‡∏°‡πà‡∏û‡∏ö API Key ‡πÉ‡∏ô Settings")
    st.stop()

# ‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏°‡∏ï‡πà‡∏≠‡∏Å‡∏±‡∏ö‡∏™‡∏°‡∏≠‡∏á AI
genai.configure(api_key=st.secrets["GEMINI_API_KEY"])
model = genai.GenerativeModel('gemini-1.5-flash')

# --- [‡∏™‡πà‡∏ß‡∏ô‡∏ó‡∏µ‡πà 2: ‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏¢‡∏ô‡∏ï‡πå (Define Engine)] ---
# ‡∏ô‡∏µ‡πà‡∏Ñ‡∏∑‡∏≠‡∏Ñ‡∏≥‡∏™‡∏±‡πà‡∏á def ‡∏ó‡∏µ‡πà‡∏Ñ‡∏∏‡∏ì‡∏ñ‡∏≤‡∏°‡∏´‡∏≤ (‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏£‡∏≠‡πÑ‡∏ß‡πâ)
def real_ai_engine(duration, fs, params):
    t = np.linspace(0, duration, int(fs * duration))
    
    # [‡∏à‡∏∏‡∏î‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏Ñ‡∏ß‡∏≤‡∏°‡∏à‡∏£‡∏¥‡∏á]: ‡∏£‡∏±‡∏ö‡∏Ñ‡πà‡∏≤‡∏à‡∏≤‡∏Å params ‡πÄ‡∏ó‡πà‡∏≤‡∏ô‡∏±‡πâ‡∏ô (‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏Å‡∏≤‡∏£‡∏Å‡∏≥‡∏´‡∏ô‡∏î‡πÄ‡∏•‡∏Ç‡πÄ‡∏≠‡∏á)
    freq = params.get('frequency', 174)      # <--- ‡∏£‡∏±‡∏ö‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ñ‡∏µ‡πà‡∏à‡∏≤‡∏Å AI
    beat = params.get('binaural_beat', 6)    # <--- ‡∏£‡∏±‡∏ö‡∏à‡∏±‡∏á‡∏´‡∏ß‡∏∞‡∏à‡∏≤‡∏Å AI
    speed = params.get('breath_speed', 0.2)  # <--- ‡∏£‡∏±‡∏ö‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏£‡πá‡∏ß‡∏´‡∏≤‡∏¢‡πÉ‡∏à‡∏à‡∏≤‡∏Å AI
    
    # ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏Ñ‡∏•‡∏∑‡πà‡∏ô‡πÄ‡∏™‡∏µ‡∏¢‡∏á (Physics Logic)
    left = 0.5 * np.sin(2 * np.pi * freq * t)
    right = 0.5 * np.sin(2 * np.pi * (freq + beat) * t)
    
    # Effect ‡∏Å‡∏≤‡∏£‡∏´‡∏≤‡∏¢‡πÉ‡∏à (Modulation)
    lfo = 0.5 + 0.5 * np.sin(2 * np.pi * speed * t)
    
    # ‡∏£‡∏ß‡∏°‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡∏ã‡πâ‡∏≤‡∏¢‡∏Ç‡∏ß‡∏≤
    audio = np.vstack((left*lfo, right*lfo)).T * 0.5
    return audio, freq, lfo

# --- [‡∏™‡πà‡∏ß‡∏ô‡∏ó‡∏µ‡πà 3: ‡∏´‡∏ô‡πâ‡∏≤‡∏à‡∏≠‡∏™‡∏±‡πà‡∏á‡∏á‡∏≤‡∏ô (User Interface)] ---
st.title("üß¨ SYNAPSE: AI-Core Integration")
st.caption("Status: Ready to Link Logic & Sound")

user_input = st.text_input("‡∏£‡∏∞‡∏ö‡∏∏‡∏Ñ‡∏ß‡∏≤‡∏°‡∏£‡∏π‡πâ‡∏™‡∏∂‡∏Å (Input Signal):")

# --- [‡∏™‡πà‡∏ß‡∏ô‡∏ó‡∏µ‡πà 4: ‡∏™‡∏ß‡∏¥‡∏ï‡∏ä‡πå‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ó‡∏≥‡∏á‡∏≤‡∏ô (Execution Trigger)] ---
# ‡∏ô‡∏µ‡πà‡∏Ñ‡∏∑‡∏≠‡∏Ñ‡∏≥‡∏™‡∏±‡πà‡∏á if st.button ‡∏ó‡∏µ‡πà‡∏™‡∏±‡πà‡∏á‡πÉ‡∏´‡πâ‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏£‡∏∞‡∏ö‡∏ö
if st.button("START PROCESS"):
    if not user_input:
        st.warning("‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡∏õ‡πâ‡∏≠‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏Å‡πà‡∏≠‡∏ô‡∏™‡∏ï‡∏≤‡∏£‡πå‡∏ó‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á")
    else:
        with st.status("‚öôÔ∏è Executing Neural Protocol...", expanded=True):
            
            # A. ‡∏™‡∏±‡πà‡∏á‡∏á‡∏≤‡∏ô AI (Prompting)
            st.write("1. Sending signal to Gemini...")
            prompt = f"""
            Analyze emotion: "{user_input}"
            Return a JSON object ONLY with these parameters:
            {{
                "frequency": (float 100-600, e.g. 174 for pain, 528 for love),
                "binaural_beat": (float 1-10),
                "breath_speed": (float 0.1-1.0),
                "message": (Thai quote ending with "‡∏≠‡∏¢‡∏π‡πà‡∏ô‡∏¥‡πà‡∏á‡πÜ ‡πÑ‡∏°‡πà‡πÄ‡∏à‡πá‡∏ö‡∏ï‡∏±‡∏ß")
            }}
            """
            
            try:
                # B. ‡∏£‡∏±‡∏ö‡∏ú‡∏•‡πÅ‡∏•‡∏∞‡πÅ‡∏õ‡∏•‡∏†‡∏≤‡∏©‡∏≤ (Listening & Parsing)
                response = model.generate_content(prompt)
                
                # ‡∏ô‡∏µ‡πà‡∏Ñ‡∏∑‡∏≠‡∏Ñ‡∏≥‡∏™‡∏±‡πà‡∏á json.loads ‡∏ó‡∏µ‡πà‡πÉ‡∏ä‡πâ‡πÅ‡∏Å‡∏∞‡∏Å‡∏•‡πà‡∏≠‡∏á‡∏Ç‡∏≠‡∏á‡∏Ç‡∏ß‡∏±‡∏ç
                match = re.search(r'\{.*\}', response.text, re.DOTALL)
                ai_data = json.loads(match.group()) 
                
                st.success("2. AI Data Decoded:")
                st.json(ai_data) # <--- ‡πÇ‡∏ä‡∏ß‡πå‡∏´‡∏•‡∏±‡∏Å‡∏ê‡∏≤‡∏ô‡∏ß‡πà‡∏≤ AI ‡∏™‡πà‡∏á‡πÄ‡∏•‡∏Ç‡∏≠‡∏∞‡πÑ‡∏£‡∏°‡∏≤
                
                # C. [‡∏à‡∏∏‡∏î‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏°‡∏ï‡πà‡∏≠‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç] (Connection Point)
                # ‡πÄ‡∏≠‡∏≤ "‡∏ô‡πâ‡∏≥‡∏°‡∏±‡∏ô" (ai_data) ‡πÄ‡∏ï‡∏¥‡∏°‡πÄ‡∏Ç‡πâ‡∏≤ "‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏¢‡∏ô‡∏ï‡πå" (real_ai_engine)
                st.write("3. Synthesizing Audio Waves...")
                y, val_freq, val_lfo = real_ai_engine(60, 44100, ai_data)
                
                # ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡πÑ‡∏ü‡∏•‡πå
                sf.write("synapse_real.wav", y, 44100)
                
                # D. ‡πÅ‡∏™‡∏î‡∏á‡∏ú‡∏• (Output)
                st.divider()
                
                # ‡∏ß‡∏≤‡∏î‡∏Å‡∏£‡∏≤‡∏ü‡∏û‡∏¥‡∏™‡∏π‡∏à‡∏ô‡πå
                fig, ax = plt.subplots(2, 1, figsize=(8, 5), facecolor='#0e1117')
                ax[0].plot(val_lfo[:500], color='#00ff00') # ‡∏Å‡∏£‡∏≤‡∏ü‡∏Å‡∏≤‡∏£‡∏´‡∏≤‡∏¢‡πÉ‡∏à
                ax[0].set_title("AI-Controlled Breathing LFO", color='white')
                ax[0].set_facecolor('#0e1117')
                
                ax[1].axhline(y=val_freq, color='#ff00ff', linewidth=3) # ‡∏Å‡∏£‡∏≤‡∏ü‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ñ‡∏µ‡πà
                ax[1].set_title(f"Target Frequency: {val_freq} Hz", color='white')
                ax[1].set_facecolor('#0e1117')
                st.pyplot(fig)
                
                # ‡πÄ‡∏•‡πà‡∏ô‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡πÅ‡∏•‡∏∞‡πÇ‡∏ä‡∏ß‡πå‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°
                st.audio("synapse_real.wav")
                st.info(f"üí¨ {ai_data['message']}")
                
            except Exception as e:
                st.error(f"‚ùå System Error: {e}")
