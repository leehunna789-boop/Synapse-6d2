import numpy as np
import streamlit as st
from scipy.io import wavfile
import matplotlib.pyplot as plt

# -----------------------------------------------------------
# 1. INPUT MODULE
# -----------------------------------------------------------
class InputModule:
    def ‡∏à‡∏±‡∏î_‡πÇ‡∏Ñ‡∏£‡∏á‡∏™‡∏£‡πâ‡∏≤‡∏á_‡∏Ñ‡∏≥‡∏™‡∏±‡πà‡∏á(self, ‡∏Ñ‡∏≥‡∏™‡∏±‡πà‡∏á‡∏Ñ‡∏≠‡∏£‡πå‡∏î, valence, arousal):
        num_chords = len([c for c in ‡∏Ñ‡∏≥‡∏™‡∏±‡πà‡∏á‡∏Ñ‡∏≠‡∏£‡πå‡∏î.split(',') if c.strip()])
        total_length = num_chords * 50 if num_chords > 0 else 200
        # ‡∏™‡∏£‡πâ‡∏≤‡∏á Sequence ‡∏à‡∏≥‡∏•‡∏≠‡∏á [Chord, Valence, Arousal]
        symbolic_sequence = np.zeros((total_length, 3))
        symbolic_sequence[:, 1] = valence
        symbolic_sequence[:, 2] = arousal
        return symbolic_sequence

# -----------------------------------------------------------
# 2. AI SYNTHESIS ENGINE (Generating Audio Logic)
# -----------------------------------------------------------
class AISynthesisEngine:
    def __init__(self, samplerate=44100):
        self.sampling_rate = samplerate

    def ‡∏™‡∏±‡∏á‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå_‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡∏™‡∏∏‡πà‡∏°_RBF(self, symbolic_sequence):
        valence = symbolic_sequence[0, 1]
        arousal = symbolic_sequence[0, 2]
        
        # ‡∏Å‡∏≥‡∏´‡∏ô‡∏î‡∏Ñ‡∏ß‡∏≤‡∏°‡∏¢‡∏≤‡∏ß 3 ‡∏ß‡∏¥‡∏ô‡∏≤‡∏ó‡∏µ
        duration = 3.0
        num_samples = int(self.sampling_rate * duration)
        
        # --- ‡∏•‡∏≠‡∏à‡∏¥‡∏Å‡∏Å‡∏≤‡∏£‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡∏™‡∏∏‡πà‡∏°‡∏ï‡∏≤‡∏°‡∏≠‡∏≤‡∏£‡∏°‡∏ì‡πå ---
        # Arousal: ‡∏Ñ‡∏ß‡∏ö‡∏Ñ‡∏∏‡∏°‡∏Ñ‡∏ß‡∏≤‡∏°‡πÅ‡∏£‡∏á (Amplitude)
        noise_amplitude = 0.1 + (arousal * 0.7)
        
        # Valence: ‡∏Ñ‡∏ß‡∏ö‡∏Ñ‡∏∏‡∏° "‡∏™‡∏µ‡∏™‡∏±‡∏ô" ‡∏Ç‡∏≠‡∏á‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡∏™‡∏∏‡πà‡∏° (‡πÉ‡∏ä‡πâ‡∏Å‡∏≤‡∏£‡∏Å‡∏£‡∏≠‡∏á‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ñ‡∏µ‡πà‡∏ï‡πà‡∏≥/‡∏™‡∏π‡∏á‡∏à‡∏≥‡∏•‡∏≠‡∏á)
        raw_noise = np.random.uniform(-1, 1, num_samples)
        
        if valence < 0.5:
            # ‡∏≠‡∏≤‡∏£‡∏°‡∏ì‡πå‡∏•‡∏ö: ‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡∏ó‡∏∂‡∏ö (Low-pass effect ‡∏á‡πà‡∏≤‡∏¢‡πÜ ‡πÇ‡∏î‡∏¢‡∏Å‡∏≤‡∏£‡πÄ‡∏Å‡∏•‡∏µ‡πà‡∏¢‡∏Ñ‡πà‡∏≤)
            raw_noise = np.convolve(raw_noise, np.ones(5)/5, mode='same')
        
        audio_out = raw_noise * noise_amplitude
        return audio_out

# -----------------------------------------------------------
# 3. MASTERING MODULE
# -----------------------------------------------------------
class MasteringModule:
    def ‡πÉ‡∏ä‡πâ_Limiter(self, audio, ceiling=0.9):
        return np.clip(audio, -ceiling, ceiling)

    def process(self, audio_raw, samplerate=44100):
        audio_limited = self.‡πÉ‡∏ä‡πâ_Limiter(audio_raw)
        # ‡πÅ‡∏õ‡∏•‡∏á‡πÄ‡∏õ‡πá‡∏ô 16-bit PCM
        audio_int16 = (audio_limited * 32767).astype(np.int16)
        return audio_int16

# -----------------------------------------------------------
# STREAMLIT UI
# -----------------------------------------------------------
st.set_page_config(page_title="RBF AI Random Sound", layout="wide")
st.title("üéµ RBF AI: Music Synthesis (Random Noise Edition)")

# Sidebar logs
st.sidebar.title("üõ†Ô∏è Engine Status")

# Layout
col_ctrl, col_viz = st.columns([1, 2])

with col_ctrl:
    st.header("Control Panel")
    chords = st.text_input("Chord Sequence", "C, G, Am, F")
    v = st.slider("Valence (‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏∏‡∏Ç)", 0.0, 1.0, 0.5)
    a = st.slider("Arousal (‡∏û‡∏•‡∏±‡∏á‡∏á‡∏≤‡∏ô)", 0.0, 1.0, 0.5)
    
    run_btn = st.button("üöÄ Start Synthesis", type="primary")

if run_btn:
    # ‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏Å‡∏£‡∏∞‡∏ö‡∏ß‡∏ô‡∏Å‡∏≤‡∏£
    input_mod = InputModule()
    engine = AISynthesisEngine()
    master = MasteringModule()

    with st.spinner("‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏™‡∏±‡∏á‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡πÄ‡∏™‡∏µ‡∏¢‡∏á..."):
        # 1. Input
        seq = input_mod.‡∏à‡∏±‡∏î_‡πÇ‡∏Ñ‡∏£‡∏á‡∏™‡∏£‡πâ‡∏≤‡∏á_‡∏Ñ‡∏≥‡∏™‡∏±‡πà‡∏á(chords, v, a)
        st.sidebar.success("Input Module: Ready")
        
        # 2. Synthesis
        raw_audio = engine.‡∏™‡∏±‡∏á‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå_‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡∏™‡∏∏‡πà‡∏°_RBF(seq)
        st.sidebar.success("AI Engine: Generated")
        
        # 3. Mastering
        final_audio = master.process(raw_audio)
        st.sidebar.success("Mastering: Complete")

    with col_viz:
        st.header("Analysis & Output")
        
        # ‡πÅ‡∏™‡∏î‡∏á‡∏Å‡∏£‡∏≤‡∏ü Waveform
        fig, ax = plt.subplots(figsize=(10, 3))
        ax.plot(raw_audio[:1000], color='#1DB954') # ‡πÅ‡∏™‡∏î‡∏á‡πÅ‡∏Ñ‡πà 1000 sample ‡πÅ‡∏£‡∏Å‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏´‡πâ‡πÄ‡∏´‡πá‡∏ô‡∏ä‡∏±‡∏î
        ax.set_title("Waveform (Zoomed)")
        ax.set_ylim(-1, 1)
        st.pyplot(fig)
        
        # ‡πÄ‡∏•‡πà‡∏ô‡πÄ‡∏™‡∏µ‡∏¢‡∏á
        audio_float = final_audio.astype(np.float32) / 32767.0
        st.audio(audio_float, format='audio/wav', sample_rate=44100)
        
        st.info(f"‡∏£‡∏∞‡∏î‡∏±‡∏ö‡∏Ñ‡∏ß‡∏≤‡∏°‡πÅ‡∏£‡∏á‡∏Ç‡∏≠‡∏á‡πÄ‡∏™‡∏µ‡∏¢‡∏á (Amplitude): {np.max(np.abs(audio_float)):.2f}")

else:
    with col_viz:
        st.info("‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡∏Å‡∏î‡∏õ‡∏∏‡πà‡∏°‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏™‡∏±‡∏á‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡∏™‡∏∏‡πà‡∏°")
