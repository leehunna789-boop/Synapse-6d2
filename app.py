import numpy as np
import streamlit as st
import google.generativeai as genai
import json, io, os, time, requests, geocoder
import pandas as pd
from scipy.io import wavfile

# --- 1. CONFIGURATION & AI CORE ---
# ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö API Key ‡∏à‡∏≤‡∏Å Streamlit Secrets ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏õ‡∏•‡∏≠‡∏î‡∏†‡∏±‡∏¢
if "GEMINI_API_KEY" in st.secrets:
    genai.configure(api_key=st.secrets["GEMINI_API_KEY"])
    # ‡πÉ‡∏ä‡πâ‡∏ä‡∏∑‡πà‡∏≠‡∏£‡∏∏‡πà‡∏ô‡∏ó‡∏µ‡πà‡∏ñ‡∏π‡∏Å‡∏ï‡πâ‡∏≠‡∏á‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÅ‡∏Å‡πâ‡∏õ‡∏±‡∏ç‡∏´‡∏≤ Error 404
    model = genai.GenerativeModel('gemini-1.5-flash')
else:
    st.error("‚ùå ‡πÑ‡∏°‡πà‡∏û‡∏ö GEMINI_API_KEY ‡πÉ‡∏ô Secrets (‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤‡πÉ‡∏ô‡∏´‡∏ô‡πâ‡∏≤ Settings > Secrets)")
    st.stop()

# ‡πÇ‡∏Ñ‡∏£‡∏á‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• (Emotional Matrix Assets)
MATRIX_V1 = {"JOY": {"F0": 0.8, "Vib": 0.9}, "SAD": {"F0": 0.3, "Vib": 0.2}}
MATRIX_V2 = {
    "JOY": {"SAT": 0.9, "LIGHT": 0.8, "CON": 0.8, "DOF": 0.3, "TEX": 0.7, "FOC": 0.9},
    "SAD": {"SAT": 0.2, "LIGHT": 0.3, "CON": 0.4, "DOF": 0.8, "TEX": 0.8, "FOC": 0.3}
}

# --- 2. REAL-WORLD DATA ENGINE (‡∏î‡∏∂‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏à‡∏£‡∏¥‡∏á) ---
def get_live_environment():
    try:
        # ‡πÉ‡∏ä‡πâ geocoder ‡∏î‡∏∂‡∏á‡∏ï‡∏≥‡πÅ‡∏´‡∏ô‡πà‡∏á‡∏à‡∏≤‡∏Å IP
        g = geocoder.ip('me') 
        lat, lon = g.latlng
        url = f"https://api.open-meteo.com/v1/forecast?latitude={lat}&longitude={lon}&current_weather=true"
        res = requests.get(url).json()
        curr = res['current_weather']
        return {
            "weather": "Rainy" if curr['weathercode'] >= 51 else "Sunny",
            "temp": curr['temperature'],
            "city": g.city if g.city else "Current Location"
        }
    except:
        # ‡∏Ñ‡πà‡∏≤ Default ‡∏Å‡∏£‡∏ì‡∏µ‡∏î‡∏∂‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÑ‡∏°‡πà‡πÑ‡∏î‡πâ
        return {"weather": "Sunny", "temp": 25.0, "city": "Unknown Location"}

# --- 3. SYNAPSE ENGINE (BIO-FEEDBACK LOGIC) ---
class SynapseEngine:
    def lerp(self, low, high, factor): return low + (high - low) * factor

    def synthesize_resonance(self, v, bpm, weather):
        sr, duration = 44100, 5
        t = np.linspace(0, duration, sr * duration)
        
        # ‡∏õ‡∏£‡∏±‡∏ö‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ñ‡∏µ‡πà‡∏ï‡∏≤‡∏°‡∏ä‡∏µ‡∏û‡∏à‡∏£‡∏à‡∏£‡∏¥‡∏á (Bio-Feedback)
        pulse_mod = 75.0 / bpm 
        f0 = self.lerp(MATRIX_V1["SAD"]["F0"], MATRIX_V1["JOY"]["F0"], v) * pulse_mod
        vib = self.lerp(MATRIX_V1["SAD"]["Vib"], MATRIX_V1["JOY"]["Vib"], v)
        
        base = 0.5 * np.sin(2 * np.pi * (432 * f0) * t + (vib * 8 * np.sin(2 * np.pi * 5 * t)))
        if weather == "Rainy":
            base += np.random.normal(0, 0.04, len(t))
            
        audio_out = (np.clip(base * 0.7, -0.9, 0.9) * 32767).astype(np.int16)
        byte_io = io.BytesIO()
        wavfile.write(byte_io, sr, audio_out)
        return byte_io.getvalue()

# --- 4. UI/UX DESIGN ---
st.set_page_config(page_title="SYNAPSE Core V3.1", layout="wide")
st.markdown("<style>.stApp { background: #000428; color: white; }</style>", unsafe_allow_html=True)

st.title("üí† SYNAPSE CORE V3.1")
st.markdown(f"*\"‡∏≠‡∏¢‡∏π‡πà‡∏ô‡∏¥‡πà‡∏á‡πÜ ‡πÑ‡∏°‡πà‡πÄ‡∏à‡πá‡∏ö‡∏ï‡∏±‡∏ß - ‡∏£‡∏∞‡∏ö‡∏ö‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£‡∏ó‡∏∏‡∏Å‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏î‡πâ‡∏ß‡∏¢‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏à‡∏£‡∏¥‡∏á\"*")

# SIDEBAR: ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏à‡∏≤‡∏Å Sensor ‡∏à‡∏£‡∏¥‡∏á
env = get_live_environment()
st.sidebar.header("üì° Live Sensor Data")
st.sidebar.info(f"üìç {env['city']} | üå°Ô∏è {env['temp']}¬∞C")
st.sidebar.write(f"‡∏™‡∏†‡∏≤‡∏û‡∏≠‡∏≤‡∏Å‡∏≤‡∏®‡∏à‡∏£‡∏¥‡∏á: **{env['weather']}**")
bpm = st.sidebar.slider("üíì Heart Rate (BPM)", 40, 160, 75)

user_input = st.text_area("‡∏õ‡πâ‡∏≠‡∏ô‡∏™‡∏†‡∏≤‡∏ß‡∏∞‡∏†‡∏≤‡∏¢‡πÉ‡∏ô‡∏Ç‡∏≠‡∏á‡∏Ñ‡∏∏‡∏ì...", placeholder="‡∏ß‡∏±‡∏ô‡∏ô‡∏µ‡πâ‡∏£‡∏π‡πâ‡∏™‡∏∂‡∏Å‡∏≠‡∏¢‡πà‡∏≤‡∏á‡πÑ‡∏£...", height=100)

engine = SynapseEngine()

if st.button("üöÄ ACTIVATE MATRIX SYNC"):
    if user_input:
        try:
            with st.status("üîÆ ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏ã‡∏¥‡∏á‡∏Ñ‡πå‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏à‡∏£‡∏¥‡∏á‡πÅ‡∏•‡∏∞ AI Matrix...", expanded=True) as status:
                # 1. AI Analysis
                prompt = f"Analyze the emotional valence of: '{user_input}'. Current weather is {env['weather']}. Return ONLY a JSON object: {{'v': 0.0-1.0}}"
                res = model.generate_content(prompt, generation_config={"response_mime_type": "application/json"})
                v = json.loads(res.text).get('v', 0.5)
                
                # 2. V2.0 Visual Mapping
                vis = {k: engine.lerp(MATRIX_V2["SAD"][k], MATRIX_V2["JOY"][k], v) for k in MATRIX_V2["JOY"]}
                
                # 3. Bio-Audio Synthesis
                audio_bytes = engine.synthesize_resonance(v, bpm, env['weather'])
                status.update(label="‚úÖ Matrix Fully Synchronized!", state="complete")

            # --- DISPLAY DASHBOARD ---
            col1, col2 = st.columns(2)
            with col1:
                st.subheader("üìä Emotional Matrix")
                st.metric("Valence (‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏∏‡∏Ç)", f"{v*100:.1f}%")
                st.line_chart(pd.DataFrame({"Waveform": np.frombuffer(audio_bytes, dtype=np.int16)[:1000]}))
                st.audio(audio_bytes, format='audio/wav')

            with col2:
                st.subheader("üé® Visual Output")
                for p, val in vis.items():
                    st.write(f"**{p}**")
                    st.progress(val)

            if bpm > 100:
                st.warning("‚ö†Ô∏è ‡∏ä‡∏µ‡∏û‡∏à‡∏£‡∏™‡∏π‡∏á: ‡∏£‡∏∞‡∏ö‡∏ö‡∏õ‡∏£‡∏±‡∏ö‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ñ‡∏µ‡πà Resonance ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏ä‡πà‡∏ß‡∏¢‡πÉ‡∏´‡πâ‡∏Ñ‡∏∏‡∏ì‡∏™‡∏á‡∏ö")
            st.balloons()
        except Exception as e:
            st.error(f"‡∏£‡∏∞‡∏ö‡∏ö‡∏Ç‡∏±‡∏î‡∏Ç‡πâ‡∏≠‡∏á: {e}")
